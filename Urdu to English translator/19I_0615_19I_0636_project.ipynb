{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "O2M-uEba2yIw"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "from torchtext.data.metrics import bleu_score\n",
        "import time\n",
        "import math\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "0XR119xj2yI0"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "Xwb8e3Au2yI2"
      },
      "outputs": [],
      "source": [
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "4tL7404h2yI4"
      },
      "outputs": [],
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "  \n",
        "    eng_lines = open('English.txt', encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "    \n",
        "    urdu_lines = open('Urdu.txt', encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "        \n",
        "    lines = []\n",
        "    for i in range(len(urdu_lines)):\n",
        "        lines.append(eng_lines[i]+\"\\t\"+urdu_lines[i])\n",
        "    pairs = []\n",
        "    for l in lines:\n",
        "        count = 0\n",
        "        onePair = []\n",
        "        for s in l.split('\\t'):\n",
        "            if count == 0:\n",
        "                onePair.append(normalizeString(s))\n",
        "            else:\n",
        "                onePair.append(s)\n",
        "            count+=1\n",
        "        pairs.append(onePair)\n",
        "\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "wd5__F5P2yI5"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "L7xTgiit2yI6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qe6T8_aJ2yI7",
        "outputId": "d6bb1ca3-87dc-4e4e-958e-c559a60507d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 100000 sentence pairs\n",
            "Trimmed to 324 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "urdu 700\n",
            "eng 590\n",
            "['ہمیں معاشی بحران کا سامنا ہے۔', 'we are facing an economic crisis .']\n"
          ]
        }
      ],
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'urdu', True)\n",
        "print(random.choice(pairs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "nt0HqRRj2yI-"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "0GBCVTxh2yJA"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "iqZLpUMN2yJB"
      },
      "outputs": [],
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "kRcndxsM2yJC"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "ZmpRzFde2yJD"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]\n",
        "\n",
        "    else:      \n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "Hd4lsqkw2yJF"
      },
      "outputs": [],
      "source": [
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    \n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "LY3grTUP82SE"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "UzGUhZ9g2yJG"
      },
      "outputs": [],
      "source": [
        "def training_iteration(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  \n",
        "    plot_loss_total = 0 \n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    return plot_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "qgi9iPks2yJG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "JF8GQm6F2yJH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "znm5-F-Q2yJI"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "jS8kRzx42yJJ"
      },
      "outputs": [],
      "source": [
        "def eval(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('Input:', pair[0])\n",
        "        print('Expected:', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('Output:', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZbaC_HA2yJJ",
        "outputId": "a69272de-57e7-4d9e-d361-58f9435aad56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0m 0s (- 0m 0s) (10 20%) 5.6179\n",
            "0m 0s (- 0m 0s) (20 40%) 4.7478\n",
            "0m 0s (- 0m 0s) (30 60%) 4.5649\n",
            "0m 0s (- 0m 0s) (40 80%) 4.5604\n",
            "0m 0s (- 0m 0s) (50 100%) 3.2658\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "loss=training_iteration(encoder1, attn_decoder1, 50000, print_every=5000)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "fig, ax = plt.subplots()\n",
        "loc = ticker.MultipleLocator(base=0.2)\n",
        "ax.yaxis.set_major_locator(loc)\n",
        "plt.plot(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "_dGkbrnY_pAV",
        "outputId": "897311d5-1fee-45dd-9c13-e10eb15bb904"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9ce303c4f0>]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc7lWAbG2yJK",
        "outputId": "d93fbf07-4323-4214-8cc1-a72024783894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: وہ وزیر اعظم منتخب کرنے والے ہیں۔\n",
            "Expected: they are about to elect a prime minister .\n",
            "Output: i are are <EOS>\n",
            "\n",
            "Input: ہم ہلاک ہو رہی کر رہے ہیں.\n",
            "Expected: we re getting killed .\n",
            "Output: i are are <EOS>\n",
            "\n",
            "Input: میں بھی اس میں انٹرسٹڈ ہوں ۔\n",
            "Expected: i am also interested in it .\n",
            "Output: i are <EOS>\n",
            "\n",
            "Input: جہاں دیکھیں تواپرات وہیں گنوائیں ساری رات ۔\n",
            "Expected: i am for him who gives me most .\n",
            "Output: i are are <EOS>\n",
            "\n",
            "Input: وہ جینے کے لئے نہیں ہیں۔ \"\n",
            "Expected: they re not for the living . \n",
            "Output: i are are <EOS>\n",
            "\n",
            "Input: تم وہ یہیں کیا کرنے والے ہیں؟\n",
            "Expected: you re gonna do that right here ?\n",
            "Output: i are are <EOS>\n",
            "\n",
            "Input: Ipb کا تو میں بھی دیوانہ ہوں ۔\n",
            "Expected: i am also crazy about ipb .\n",
            "Output: i are <EOS>\n",
            "\n",
            "Input: ہم یہاں ووٹ ڈالنے کے لئے موجود ہیں۔\n",
            "Expected: we are here to vote .\n",
            "Output: i are are <EOS>\n",
            "\n",
            "Input: مٹی کی رسی بانٹنا ! ۔\n",
            "Expected: you are weaving a rope out of sand .\n",
            "Output: i are <EOS>\n",
            "\n",
            "Input: ہم پرامید ہیں کہ کیا ہوسکتا ہے۔ \"\n",
            "Expected: we re optimistic about what might happen . \n",
            "Output: i are <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "eval(encoder1, attn_decoder1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "wYn84Ndh2yJL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "a9cff5a362bc38ef45d817ae74b1af54d6a076e3d773891282bce078b815ba34"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}